<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Scheduler and RM load tests</title>
</head>

<body>
<h1>Scheduler and RM load tests</h1>

<h2>Contents</h2>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#deploy_config">Deployment configuration</a></li>
    <ul>
        <li><a href="#deploy_rm">Resource Manager test</a></li>
        <ul>
            <li><a href="#">Execution with already running RM</a></li>
            <li><a href="#">Automatically deploy RM</a></li>
        </ul>
        <li><a href="#deploy_scheduler">Scheduler test</a></li>
        <ul>
            <li><a href="#">Execution with already running Scheduler</a></li>
            <li><a href="#">Automatically deploy Scheduler and RM</a></li>
        </ul>
        <li><a href="#">Execution with hosts provided by the existing Scheduler</a></li>
        <li><a href="#deploy_db">Database configuration</a></li>
        <li><a href="#config_log">Logging configuration</a></li>
    </ul>
<li><a href="#test_params">Test parameters</a></li>
    <ul>
        <li><a href="#test_params_common">Common tests parameters</a></li>
        <li><a href="#test_params_rm">RM tests parameters</a></li>
        <li><a href="#test_params_scheduler">Scheduler tests parameters</a></li>
    </ul>
<li><a href="#examples">Examples</a></li>
    <ul>
        <li><a href="#examples_rm">RM test</a></li>
        <li><a href="#examples_scheduler">Scheduler test</a></li>
    </ul>
</ul>

<h2><a id="overview">Overview</a></h2>

<p>
Directory 'performance' contains jmeter-based tests for Scheduler and Resource Manager (RM). These tests are mainly intended for load testing, but also they can be used to measure performance of some Scheduler and Resource Manager functionality.
</p>

<p>
Tests are organized as set of small and independent scenarios, each test scenario represents some meaningful usage of Scheduler or RM functionality (for example submit Scheduler task or request nodes from RM). 
To simulate heavy load on server and leverage reporting functionality  <a href="http://jmeter.apache.org/index.html">Apache JMeterâ„¢</a> framework was used for tests implementation. 
</p>

<p>
Each JMeter test consists of set of <a href="http://jmeter.apache.org/usermanual/test_plan.html#samplers">samplers</a> which tell JMeter how to send requests to a server 
 (in these tests only custom <a href="http://jmeter.apache.org/api/org/apache/jmeter/protocol/java/sampler/JavaSampler.html">JavaSamplers</a> are used) and 
<a href="http://jmeter.apache.org/usermanual/test_plan.html#thread_group">ThreadGroups</a> which control the number of threads JMeter uses to execute each sampler.
JMeter repeatedly executes samplers in parallel from multiple threads during specified amount of time, when executing completes report with information for each sampler is generated (report shows how many times sampler was executed, minimum, maximum and average execution time).    
</p>
<p>
For example in Scheduler test there is a sampler submitting java task to the Scheduler and another sampler connecting and disconnecting from the Scheduler. 
These samplers are implemented as custom JavaSamplers (classes SimpleJavaJobSubmitClient and SchedulerConnectClient) and they are associated with dedicated thread groups repeatedly executing these samples.
Number of threads in each ThreadGroup is configurable and for example it is possible to 
run for 10 hours test submitting tasks from 10 threads and executing connect/disconnect from 5 threads.   
</p>

<p>
Tests can be run in the multiple modes:
</p>
<ul>
<li>mode when tests are executed against already deployed Scheduler and RM</li>
<li>mode when before execution tests automatically deploy Scheduler, RM and RM nodes on the hosts explicitly specified in the tests parameters (all started processes are automatically killed when test completes)</li> 
<li>mode when  before execution tests automatically deploy Scheduler, RM and RM nodes on the hosts received from the existing Scheduler (all started processes are automatically killed when test completes)</li>
</ul>

<p>
Tests are executed by the ant script (build.xml), lists of available ant targets can be displayed using standard command 'ant -p'.
To execute tests a number of various configuration parameters should be specified, these parameters should be set in the properties files:  
</p>
<ul>
<li><b>common.test.properties</b> common deployment and test parameters</li>
<li><b>rm.test.properties</b> properties related to RM deployment and RM test scenarios parameters</li>
<li><b>scheduler.test.properties</b> properties related to Scheduler deployment and Scheduler test scenarios parameters</li>
</ul>

And here is a list of sub-directories located in the 'performance' directory:
<ul>
<li><b>config/</b> contains various configuration (log4j configuration for Scheduler and RM, database  configuration for Scheduler and RM, etc)</li>
<li><b>jmeter/</b> contains jmeter testplans</li>
<li><b>lib/</b> jmeter binaries needed to compile tests</li>
<li><b>results/</b> contains results of test execution and reports</li>
<li><b>src/</b> tests sources</li>
<li><b>tmp/</b> directory where tests create various temporary files</li>
</ul>

<p>To execute tests it is necessary to provide two kinds of configuration parameters:</p>
<ul>
<li>information how to deploy Scheduler and RM, or if tests are run against already started servers just connection information</li>
<li>tests execution parameters (what scenarios should be executed, how many simultaneous threads should be started, etc)</li>
</ul>
<p>
Next sections describe all these parameters.
</p> 

<h2><a id="deploy_config">Deployment configuration</a></h2>
Next sections explain what deployment configuration is needed depending on the chosen execution mode.

<h3><a id="deploy_config_rm">Resource Manager test</a></h3>
This section explains deployment configuration necessary to execute RM tests. Before executing RM tests it necessary to start RM with nodes (and additionally PAMR router if PAMR protocol is used).

<h4><a id="deploy_config_rm_existing">Execution with already running RM</a></h4>
<p>
This mode assumes that RM with nodes are already running, so it is necessary to provide only information required to connect to the RM:
</p>    
<ul>
<li><b>rmUrl</b> (rm.test.properties): URL used by the tests to connect to the RM</li>
</ul>
JMeter java process running tests uses ProActive configuration file 'config/DefaultClientProActiveConfiguration.xml', so if additional ProActive parameters required for connection should be set (e.g. PAMR router properties) this should be done in this file. 

<h4><a id="deploy_config_rm_auto_deploy">Automatically deploy RM and nodes</a></h4>
<p>
In this mode tests automatically start RM with nodes and various deployment parameters should be set. 
</p>
<p>
<b>Note:</b> tests start processes on remote hosts using SSH, so all hosts specified in the deployment configuration
should be accessible by the SSH from the host where tests are executed. 
</p>

<ul>
<li><b>test.deploy.protocol</b> (common.test.properties) ProActive protocol used to deploy Scheduler and Resource Manager, supported values are pnp, pamr or rmi</li>
<li><b>rm.deploy.rmHost</b> (rm.test.properties) host where RM should be stared</li>
<li><b>rm.deploy.javaOpts</b> (rm.test.properties) options for JVM running RM</li>
<li><b>rm.deploy.dropDB</b> (rm.test.properties) if RM should cleanup its database during start-up</li>
<li><b>rm.deploy.rmNodesHosts</b> (rm.test.properties) host where RM should deploy nodes</li>
<li><b>rm.deploy.rmNodesPerHosts</b> (rm.test.properties) how many nodes RM should start on each host after start-up</li>
<li><b>optional rm.deploy.rmNodesSourcesNumber</b> (rm.test.properties) how many NodeSources should use RM to deploy
nodes (1 by default), this value can't be bigger then number of available hosts. 
If it is more than one then RM equally divides available hosts between all NodeSources </li>
</ul>

<h4><a id="deploy_pamr">PAMR router parameters:</a></h4>
<p>
If PAMR protocol is used for RM deployment then additional parameters should be set.
</p>
<p>
If tests should automatically start PAMR router then following parameters are required:
</p>
<ul>
<li><b>test.deploy.pamr.startNewRouter.host</b> (common.test.properties) host where PARM router should be started</li>
<li>optional parameter <b>test.deploy.pamr.startNewRouter.args</b> (common.test.properties) PAMR router command line parameters (e.g. -v -t 540000 -w 16)</li>
<li>optional parameter <b>test.deploy.pamr.startNewRouter.port</b> (common.test.properties) PAMR router port to be used, if not specified then port will be chosen automatically</li>
</ul>
<p>
If already running PAMR router should be used then following parameters are required:
</p>
<ul>
<li><b>test.deploy.pamr.existingRouterHost</b> (common.test.properties) host where PAMR router is running</li>
<li><b>test.deploy.pamr.existingRouterPort</b> (common.test.properties) PAMR router port</li>
</ul>

<h4><a id="deploy_amqp">AMQP broker parameters:</a></h4>
<p>
If AMQP protocol is used for RM deployment then additional parameters should be set.
</p>
<p>
Tests don't start AMQP broker, broker should be started manually and following test parameters should be set:
</p>
<ul>
<li><b>test.deploy.amqp.host</b> (common.test.properties) AMQP broker host</li>
<li><b>test.deploy.amqp.port</b> (common.test.properties) AMQP broker port</li>
<li>optional parameter <b>test.deploy.amqp.user</b> (common.test.properties) AMQP broker user</li>
<li>optional parameter <b>test.deploy.amqp.password</b> (common.test.properties) AMQP broker password</li>
<li>optional parameter <b>test.deploy.amqp.socketfactory</b> (common.test.properties) socket factory used to establish connection
to the AMQP broker. It can be 'plain' if regular socket factory should be used, or 'ssh' if sockets using ssh tunnel should be used.</li>
<li>optional parameter <b>test.deploy.amqp.ssh.key_directory</b> (common.test.properties) parameter of ssh tunnel connection, can be set if ssh tunnel is used to connect to the broker</li>
<li>optional parameter <b>test.deploy.amqp.ssh.known_hosts</b> (common.test.properties) parameter of ssh tunnel connection, can be set if ssh tunnel is used to connect to the broker</li>
<li>optional parameter <b>test.deploy.amqp.ssh.username</b> (common.test.properties) parameter of ssh tunnel connection, can be set if ssh tunnel is used to connect to the broker</li>
<li>optional parameter <b>test.deploy.amqp.ssh.port</b> (common.test.properties) parameter of ssh tunnel connection, can be set if ssh tunnel is used to connect to the broker</li>
</ul>
<p>

<h3><a id="deploy_config_scheduler">Scheduler test</a></h3>
This section explains deployment configuration necessary to execute Scheduler test. Before executing Scheduler test it necessary 
to start RM with nodes and Scheduler (and additionally PAMR router if PAMR protocol is used).

<h4><a id="deploy_config_scheduler_existing">Execution with already running Scheduler</a></h4>
<p>
This mode assumes that Scheduler and RM with nodes are already running, so it is necessary to provide only information required 
to connect to the Scheduler:
</p>    
<ul>
<li><b>targetSchedulerUrl</b> (scheduler.test.properties): URL used by the tests to connect to Scheduler</li>
</ul>
<p>
JMeter java process running tests uses ProActive configuration file 'config/DefaultClientProActiveConfiguration.xml', so if additional ProActive parameters required for connection should be set (e.g. PAMR router properties) this should be done in this file. 
</p>


<h4><a id="deploy_config_scheduler_auto_deploy">Deploy Scheduler and RM before tests execution</a></h4>
<p>
In this mode tests automatically start Scheduler and RM with nodes and various deployment parameters should be set. 
</p>
<p>
<b>Note:</b> tests start processes on remote hosts using SSH, so all hosts specified in the deployment configuration
should be accessible by the SSH from the host where tests are executed. 
</p>

<ul>
<li><b>test.deploy.protocol</b> (common.test.properties) ProActive protocol used to deploy Scheduler and Resource Manager, supported values are pnp, pamr or rmi</li>
<li><b>scheduler.deploy.schedulerHost</b> (scheduler.test.properties) host where Scheduler should be stared</li>
<li><b>scheduler.deploy.javaOpts</b> (scheduler.test.properties) options for JVM running Scheduler</li>
<li><b>scheduler.deploy.dropDB</b> (scheduler.test.properties) if Scheduler should cleanup its database during start-up</li>
<li><b>rm.deploy.rmHost</b> (rm.test.properties) host where RM should be stared</li>
<li><b>rm.deploy.javaOpts</b> (rm.test.properties) options for JVM running RM</li>
<li><b>rm.deploy.dropDB</b> (rm.test.properties) if RM should cleanup its database during start-up</li>
<li><b>rm.deploy.rmNodesHosts</b> (rm.test.properties) host where RM should deploy nodes</li>
<li><b>rm.deploy.rmNodesPerHosts</b> (rm.test.properties) how many nodes RM should start on each host</li>
</ul>

<p>
If PAMR protocol is used for Scheduler and RM deployment then additional <a href="#deploy_pamr">PAMR parameters</a> should be set.
</p>
<p>
If AMQP protocol is used for Scheduler and RM deployment then additional <a href="#deploy_amqp">AMQP broker parameters</a> should be set.
</p>

  
<h3><a id="deploy_config_nodes_from_scheduler">Execution using hosts provided by the existing Scheduler</a></h3>
<p>
This mode assumes that there are hosts managed by the stable Scheduler and RM installation. In this mode
to execute tests special multi-node task is submitted to this existing Scheduler.
This task receives from the Scheduler set of hosts (number of hosts to request is configurable)
and uses these hosts to deploy Scheduler, RM with nodes and to execute tests  
(this multi-node task is created with topology descriptor DIFFERENT_HOSTS_EXCLUSIVE so received hosts can not be used by the others tasks).
</p>
<p>
To execute tests in this mode it is necessary to specify information required to connect to the existing Scheduler which will provide hosts:  
</p> 
<ul>
<li><b>get.hosts.from.scheduler.schedulerUrl</b> (common.test.properties) Scheduler connection URL</li>
<li><b>get.hosts.from.scheduler.schedulerLogin</b> (common.test.properties) Scheduler connection login</li>
<li><b>get.hosts.from.scheduler.schedulerPassword</b> (common.test.properties) Scheduler connection password</li>
<li><b>get.hosts.from.scheduler.clientSchedulingPath</b> (common.test.properties) version of the Scheduler providing hosts can differ from the version of the Scheduler under test, this parameter specifies path to the Scheduler project containing binaries which are used to connect to the Scheduler providing hosts</li>
<li><b>get.hosts.from.scheduler.clientProActiveConfig</b> (common.test.properties) ProActive configuration file used to connect to the Scheduler (for example if Scheduler is deployed with PAMR protocol this configuration can contain properties of the PAMR router)</li>
<li><b>get.hosts.from.scheduler.rmHostsNumber</b> (common.test.properties) number of hosts requested from the Scheduler which will be used the the tested RM to deploy nodes</li>
<li>optional parameter <b>get.hosts.from.scheduler.rmAdditionalHostsNumber</b> (common.test.properties) number of additional hosts requested from the Scheduler (these hosts are used only by the RM test scenarios deploying node sources)</li>
<li><b>get.hosts.from.scheduler.targetToRun</b> (common.test.properties) whether RM or Scheduler tests should be executed. To run RM test use value deploy-rm-and-execute-test, to run Scheduler test deploy-rm-and-scheduler-and-execute-test.</li>
</ul>
<b>Note: </b>total number of hosts requested from the Scheduler is 'rmHostsNumber + rmAdditionalHostsNumber + 1 (host where jmeter tests are executed) + 1 (host where Scheduler and RM are deployed)'.
Make sure Scheduler really has so so many hosts.  

<h3><a id="deploy_db">Database configuration</a></h3>
<p>
Scheduler and RM automatically deployed by the tests use database configuration
specified respectively in the files 'config/scheduler/scheduler.hibernate.cfg.xml' and 'config/rm/rm.hibernate.cfg.xml'.
So if database settings should be changed these files should be modified.
</p>
<p>
By default derby database is used (derby creates its files in the 'tmp' directory). 
</p>

<h3><a id="config_log">Logging configuration</a></h3>
<p>
Log4j configuration for different RM/Scheduler components is defined in the files located in the 'performance/config/log4j':
</p>
<ul>
    <li><b>log4j-rm-server</b> log4j configuration used by the RM</li>
    <li><b>log4j-client</b> log4j configuration used by the deplyed RM nodes</li> 
    <li><b>log4j-scheduler-server</b> log4j configuration used by the Scheduler</li>
    <li><b>log4j-forkedTask</b> log4j configuration used by the forked java tasks</li>
    <li><b>log4j-pamr-router</b> log4j configuration used by the PAMR router</li>
</ul>    

<h2><a id="test_params">Test parameters</a></h2>
Next sections explain parameters controlling tests execution.

<h3><a id="test_params_common">Common tests parameters</a></h3>
This section describes parameters which are common for both Scheduler and RM tests.

<ul>
<li><b>jmeterhome</b> (common.test.properties) path to jmeter (tests were developed with jmeter-2.5.1, so this version is recommended)</li>
<li><b>testTime</b> (common.test.properties) how long test should execute (time is in seconds)</li>
<li><b>stopOnError</b> (common.test.properties) this parameter controls tests behavior in case if during execution some of the tests 
gets an error. If stopOnError=true then tests execution is interrupted in case of any error. If stopOnError=false then 
even if an error occurs tests continue execution until test end time is reached, and information about all errors will be available in the report</li>
<li><b>javaPath</b> (common.test.properties) absolute path to the java executable which is used to start all test processes (Scheduler, RM, etc).
This path should be valid on all the hosts where processes are started. </li>
<li><b>schedulingPath</b> (common.test.properties) absolute path to the tested Scheduler project. This path should be valid on all the hosts where processes are started. </li>
</ul>

<h3><a id="test_params_rm">RM test parameters</a></h3>
<p>
RM test consists of independent scenarios which are repeatedly executed by the JMeter from multiple threads. Each scenario tries to
use some RM functionality in meaningful way and measures time required to accomplish scenario. 
This section describes parameters of the all RM test scenarios.
</p>
<h4>Request Nodes scenario</h4> 
This scenario is implemented in the NodesRequestRMClient class. Scenario requests nodes using ResourceManager.getAtMostNodes() and
immediately releases received nodes using ResourceManager.releaseNodes(). It measures total time required to complete these two RM calls.  
<p>
Configurable parameters:
</p>
<ul>
<li><b>nodeRequestUsers</b> (rm.test.properties) number of threads executing scenario</li>
<li><b>requestedNodesNumber</b> (rm.test.properties) how many nodes is requested by the single scenario iteration</li>
<li><b>nodeRequestTopology</b> (rm.test.properties) topology parameter for the node request (one of the ARBITRARY, BEST_PROXIMITY, DIFFERENT_HOSTS_EXCLUSIVE, MULTIPLE_HOSTS_EXCLUSIVE, SINGLE_HOST, SINGLE_HOST_EXCLUSIVE)</li>
<li><b>useSelectionScript</b> (rm.test.properties) is selection script should be used for node request. If 'true' then test uses simple script which always returns 'true'.</li>
<li><b>selectionScriptTypeDynamic</b> (rm.test.properties) is static or dynamic selection script should be used (parameter makes sense only is useSelectionScript is true)</li>
<li><b>selectionScriptDynamicContent</b> (rm.test.properties) is content of the selection script should be different on each iteration (parameter makes sense only is useSelectionScript is true).
If this parameter is 'true' then script still always returns 'true' but test on each iteration inserts some random string in the script text, it is used to stress RM's logic which tries to predict script execution result using script content hash.</li>
</ul>

<h4>Use RM JMX scenario</h4> 
This scenario is implemented in the RMJMXClient class. Scenario connects to the JMX interface provided by the RM and invokes various operations provided by the RM MBeans. It measures time required to connect to JMX, execute getters on all beans and disconnect.  

<h4>Create node source scenarios</h4> 
There are two scenarios creating new node sources. One scenario uses SSH Infrastructure and another one Command Line infrastructure
(scenarios are implemented in the SSHInfrastructureNodeSourceCreateClient and CLIInfrastructureNodeSourceCreateClient).
Both scenario work in the same way: create new nodes source using ResourceManager.createNodeSource, wait when
deployment of all nodes in the created node source completes and then remove node source using ResourceManager.removeNodeSource.
Scenarios measure total time required to create node source and deploy all nodes. 
<p>
In these scenarios all nodes of the created source are deployed on the single host, list of hosts which 
should be used for nodes deployment is specified as <b>createNodeSourceHosts</b> parameter.
Note: if multiple  threads execute scenarios concurrently they will pick 
hosts from the list so that the same host isn't used concurrently by multiple threads, but if number of threads executing scenarios is bigger then number of 
available hosts then multiple threads will concurrently deploy nodes on the same host, it can some impact
on the execution.
</p>

<p>
Configurable parameters:
</p>
<ul>
<li><b>nodeJavaOptions</b> (rm.test.properties) options for JVM running deployed nodes</li>
<li><b>createNodeSourceHosts</b> (rm.test.properties) hosts used to deploy nodes</li>
<li><b>createNodeSourceNodesPerHost</b> (rm.test.properties) how many nodes each node source deploys</li>
<li><b>sshNodeSourceUsers</b> (rm.test.properties) number of threads executing scenario with SSH Infrastructure</li>
<li><b>cliNodeSourceUsers</b> (rm.test.properties) number of threads executing scenario with  Command Line Infrastructure</li>
<li><b>cliUseDefaultScripts</b> (rm.test.properties) is default scripts should be used in the Command Line Infrastructure scenario. Default deployment script is generated dynamically using template script 'src/org/ow2/proactive/tests/performance/jmeter/rm/defaultSSHDeployment'. Default removal script is empty.</li>
<li>optional parameter <b>cliNodeDeploymentScript</b> (rm.test.properties) path to the deployment script to be used by Command Line Infrastructure scenario (required if cliUseDefaultScripts=false)</li>
<li>optional parameter <b>cliNodeRemovalScript</b> (rm.test.properties) path to the removal script to be used by Command Line Infrastructure scenario (required if cliUseDefaultScripts=false) </li>
</ul>

<h4>Event handling load</h4>
To additionally load RM's events dispatching system it is possible to create dummy event listeners which are registered when test execution starts and 
removed when test finishes (code of listener methods does nothing).
  
<ul>
<li><b>rmListenersNumber</b> (rm.test.properties) number of dummy event listeners which are registered at the beginning of the test execution</li>
</ul>

<h3><a id="test_params_scheduler">Scheduler test parameters</a></h3>
<p>
Scheduler test consists of independent scenarios which are repeatedly executed by the JMeter from multiple threads. Each scenario tries to
use some Scheduler functionality in meaningful way and measures time required to accomplish scenario. 
This section describes parameters of the all Scheduler test scenarios.
</p>

<p>
There are multiple test scenarios working in the same way: submit some job to the Scheduler using Scheduler.submit and wait when job execution completes.
Time required to execute Scheduler.submit is measured. Scenarios differ only in the type of the submitted job. All these scenarios
have common parameters:
</p>

<ul>
<li><b>submitUseSelectionScript</b> (scheduler.test.properties) is submitted tasks should have selection script. If 'true' then test uses simple script which always returns 'true'.</li>
<li><b>submitSelectionScriptTypeDynamic</b> (scheduler.test.properties) is static or dynamic selection script should be used (parameter makes sense only is submitUseSelectionScript is true)</li>
<li><b>submitSelectionScriptDynamicContent</b> (scheduler.test.properties) is content of the selection script should be different on each iteration (parameter makes sense only is submitUseSelectionScript is true).
If this parameter is 'true' then script still always returns 'true' but test on each iteration inserts some random string in the script text, it is used to stress RM's logic which tries to predict script execution result using script content hash.</li>
</ul>
    

<h4>Submit simple java task scenario</h4> 
This scenario is implemented in the SimpleJavaJobSubmitClient class. Scenario submits job which contains single forked java task, task just sleeps for 5 seconds and finishes.   
<p>
Configurable parameters:
</p>
<ul>
<li><b>simpleJavaTaskUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
</ul>

<h4>Submit simple native task scenario</h4> 
This scenario is implemented in the SimpleNativeJobSubmitClient class. Scenario submits job which contains single native task, 
native task's script just sleep 5 seconds and finishes.   
<p>
Configurable parameters:
</p>
<ul>
<li><b>simpleNativeTaskUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
</ul>

<h4>Submit multi-node task scenario</h4> 
This scenario is implemented in the MultiNodeJobSubmitClient class. Scenario submits job which contains single multi-node task (task doesn't do anything just sleeps some time and finishes).   
<p>
Configurable parameters:
</p>
<ul>
<li><b>multiNodeSubmitUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
<li><b>multiNodeSubmitTaskType</b> (scheduler.test.properties) type of the submitted task (java_task or native_task)</li>
<li><b>multiNodeSubmitNodesNumber</b> (scheduler.test.properties) how many nodes is requested by the task </li>
<li><b>multiNodeSubmitTopology</b> (scheduler.test.properties) topology descriptor for the nodes request (one of the ARBITRARY, BEST_PROXIMITY, DIFFERENT_HOSTS_EXCLUSIVE, MULTIPLE_HOSTS_EXCLUSIVE, SINGLE_HOST, SINGLE_HOST_EXCLUSIVE) </li>
</ul>

<h4>Submit dependent tasks scenario</h4> 
This scenario is implemented in the DependentTasksSubmitClient class. Scenario submits job which contains tasks with dependencies (tasks don't do anything just sleep some time and finish).   
Job contains following tasks: one 'first task', N 'dependent tasks' depending on the 'first task' and one 'last task' depending on the all 'dependent tasks'.   
<p>
Configurable parameters:
</p>
<ul>
<li><b>submitDependentTasksUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
<li><b>dependentTasksSubmitTaskType</b> (scheduler.test.properties) type of the submitted tasks (java_task or native_task)</li>
<li><b>dependentTasksSubmitTasksNumber</b> (scheduler.test.properties) number of 'dependent tasks'</li>
</ul>

<h4>Submit replicate workflow tasks scenario</h4> 
This scenario is implemented in the ReplicateTaskSubmitClient class. Scenario submits job with replicated tasks.
Workflow schema is following (task B is replicated N times):
<pre>
         A
         |
 --------------------
 |    |     |  |    |
 B_1  B_2   ....   B_N
 ------------------
         |
         C
</pre>

<p>
Configurable parameters:
</p>
<ul>
<li><b>replicateTasksUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
<li><b>replicateTasksSubmitTaskType</b> (scheduler.test.properties) type of the submitted tasks (java_task or native_task)</li>
<li><b>replicateTasksSubmitChildrenNumber</b> (scheduler.test.properties) how many times task B is replicated</li>
</ul>

<h4>Submit loop workflow tasks scenario</h4> 
This scenario is implemented in the LoopTaskSubmitClient class. Scenario submits job with task executed in the loop 
(job has two tasks, second task depends on the first and second task is executed in the loop N times).  
<p>
Configurable parameters:
</p>
<ul>
<li><b>loopTasksUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
<li><b>loopTasksSubmitTaskType</b> (scheduler.test.properties) type of the submitted tasks (java_task or native_task)</li>
<li><b>loopTasksSubmitIterationsNumber</b> (scheduler.test.properties) number of iterations for the workflow loop</li>
</ul>

<h4>Submit sample jobs scenario</h4> 
This scenario is implemented in the SampleJobsSubmitClient class.
This scenario submits multiple jobs using jobs descriptors from the scheduler samples and waits when jobs finish.
It measures total time required to submit all jobs.  
Submitted jobs are Job_8_tasks.xml, Job_Aborted.xml, Job_fork.xml, _nativ.xml, Job_PI.xml, Job_pre_post.xml, Job_with_dep.xml, Job_with_select_script.xml.   
<p>
Configurable parameters:
</p>
<ul>
<li><b>sampleJobUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
</ul>

<h4>Submit failing task scenario</h4> 
This scenario is implemented in the SubmitFailingTaskSchedulerClient class. Scenario submits job
with two tasks which always fail: java task (throws exception) and native task (exits with code 1).  
Tasks are created with parameter maxNumberOfExecution=3 so scheduler tries to execute each task 3 times. 
<p>
Configurable parameters:
</p>
<ul>
<li><b>failingTasksUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
<li><b>failingTaskSubmitTaskType</b> (scheduler.test.properties) type of the submitted tasks (java_task or native_task)</li>
<li><b>failingTaskSubmitRestartMode</b> (scheduler.test.properties) tasks restart mode (one of ANYWHERE or ELSEWHERE)</li>
</ul>

<h4>Connect to the Scheduler scenario</h4> 
This scenario is implemented in the SchedulerConnectClient class. Scenario just establishes connection with Scheduler (SchedulerConnection.waitAndJoin), 
logins (SchedulerAuthenticationInterface.login) and immediately disconnects (Scheduler.disconnect).  
<p>
Configurable parameters:
</p>
<ul>
<li><b>schedulerConnectUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
</ul>

<h4>Submit and kill job scenario</h4> 
This scenario is implemented in the SubmitAndKillSchedulerClient class. Scenario submits job with one native task
(task sleeps forever), waits when task starts execution, kills job (Scheduler.killJob) and removes killed job (Scheduler.removedJob).
It measures time required to call Scheduler.killJob.
<p>
Configurable parameters:
</p>
<ul>
<li><b>submitAndKillUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
</ul>

<h4>Submit and kill tasks scenario</h4> 
This scenario is implemented in the SubmitAndKillTaskSchedulerClient class. This scenario submits job with two tasks 
(native and java tasks which sleep forever), waits when both tasks start execution and kills both tasks (Scheduler.killTask).
It measures total time required to kill two tasks.  
<p>
Configurable parameters:
</p>
<ul>
<li><b>submitAndKillTasksUsersNumber</b> (scheduler.test.properties) number of threads executing scenario</li>
</ul>

<h4>Use Scheduler JMX scenario</h4> 
This scenario is implemented in the SchedulerJMXClient class. Scenario connects to the JMX interface provided by the SchedulerJMXClient and invokes various operations provided by the SchedulerJMXClient MBeans. It measures time required to connect to JMX, execute getters on all beans and disconnect.  


<h4>Event handling load</h4>
To additionally load Schedulers's events dispatching system it is possible to create dummy event listeners which are registered when test execution starts and 
removed when test finishes (code of listener methods does nothing).
  
<ul>
<li><b>schedulerListenersNumber</b> (scheduler.test.properties) number of dummy event listeners which are registered at the beginning of the test execution</li>
</ul>

<h2><a id="examples">Examples</a></h2>
<p>
There are quite a lot configuration parameters, and here are some examples of tests configuration which one can use to get started with tests execution.
</p>
<p>
In these examples it is assumed that there are three hosts which are used for tests execution: host1, host2, host3 (and it should be possible to SSH to these hosts from the machine where test is run).
Scheduler project and JVM used to start test processes are located in the shared network folder which is accessible from all the hosts.
</p>

<h3><a id="examples_rm">RM test</a></h3>

<h4>Example 1</h4>

<p>
Just to check that tests are really can be run in this environment one in can try to use the simplest configuration: RM test, RM is deployed automatically, pnp protocol is used.
</p>
<p>
Here is configuration of common parameters in the <b>common.test.properties</b> which can be used for quick run:
</p>
<pre>
# Path to the jmeter, for example /user/userName/home/jakarta-jmeter-2.5.1
jmeterhome=&ltpath to jmeter&gt

# Run tests for one minute
testTime=60

# Immediately stop execution in case of error
stopOnError=true

# Path to the java executable, for example /user/userName/home/jdk/bin/java
javaPath=&ltpath to java executable&gt

# Path to the tested Scheduler project, for example /user/userName/home/Scheduler
schedulingPath=&ltpath to the tested Scheduler project&gt

# Use pnp protocol to deploy RM
test.deploy.protocol=pnp

# Parameters related to the PAMR router (empty since pnp protocol is used)
test.deploy.pamr.startNewRouter.host=
test.deploy.pamr.startNewRouter.args=
test.deploy.pamr.startNewRouter.port=
</pre>

<p>
And let's configure RM deployment and scenarios. RM will be started on the host1, it will deploys two nodes on each host2 and host3.
We'll run only scenario requesting nodes, it will be run from single thread and it will request and release one node per iteration. 
Here is <b>rm.test.properties</b> for this configuration:
</p> 
<pre>
# RM will be started on the host1
rm.deploy.rmHost=host1
# Don't set any options for the JVM running RM
rm.deploy.javaOpts=
# RM should clean it's database on start-up
rm.deploy.dropDB=true
# Host where RM will deploy nodes
rm.deploy.rmNodesHosts=host2,host3
# RM will start two nodes on each host2 and host3 
rm.deploy.rmNodesPerHosts=2

# Number of dummy RM listeners which can be registered to load RM event dispatching
rmListenersNumber=0

# Number of threads executing 'request nodes' scenario            
nodeRequestUsers=1
nodeRequestTopology=ARBITRARY
# Request one node per iteration
requestedNodesNumber=1
# Use selection script for nodes request
useSelectionScript=true

# Number of threads executing scenario 'create node sources with command line infrastructure', use zero to don't run this scenario
cliNodeSourceUsers=0
# Number of threads  executing scenario 'create node source with SSH infrastructure', use zero to don't run this scenario
sshNodeSourceUsers=0
# We don't run scenario creating node sources, so this property is empty
createNodeSourceHosts=
</pre>

<p>
Now test can be run, go to the 'performance' directory and run ant target which deploys RM and executes test: 
</p>
<pre>
>> ant deploy-rm-and-execute-test
</pre>  
<p>
At the end of the successful run ant prints message 'BUILD SUCCESSFUL', and execution results are available in the 'performance/results':
</p>
<ul>
<li><b>rm1_detail.html</b> html report with information about each executed scenario (how many times scenario was executed, 
max, min and average time, execution errors if any)</li>
<li><b>jmeter.log</b> jmeter log, test  useful to analyze tests failures</li>
</ul>

<p>
If default <a href="#config_log">logging settings</a> weren't changed then 'performance/results' also contains RM log file (PERFORMANCE_rm_server.log).
</p>
<p>
A lot of things can go wrong during deployment (e.g. some required property isn't set, host isn't reachable by SSH, path isn't available on the host, etc) or 
during tests execution. In this case ant prints message 'BUILD FAILED' and it is necessary to analyze ant output and test logs to find out reason of the failure.  
</p>

<h4><a id="example_rm_2">Example 2</a></h4>
<p>
Let's change configuration from the previous example to use pamr protocol and to run all RM scenarios. 
</p>
<p>
First, set required parameters in the <b>common.properties</b>, need to change parameter 'test.deploy.protocol' and
set PAMR router parameters (others lines aren't changed):
</p>
<pre>
# Use pamr protocol to deploy RM
test.deploy.protocol=pamr

# Start PAMR router on the same host as RM
test.deploy.pamr.startNewRouter.host=host1
# Optionally we can set number of PAMR worker threads and timeout (these are parameters supported by the start-router script):
test.deploy.pamr.startNewRouter.args=-w 16 -t 540000
# PAMR router port, leave it empty to automatically select port
test.deploy.pamr.startNewRouter.port=
</pre>
<p>
Try to run RM test with these configuration to make sure it really works.
</p>
<p>
Now let's configure execution of the scenarios deploying node sources. It is necessary to provide list of hosts
where new nodes will be stared, we'll use the same hosts which are used by the RM. Here is rm.test.properties:
</p>
<pre>
# Tests will start new nodes on the host2 and host3
createNodeSourceHosts=host2,host3
# Single thread executes scenario 'create node sources with command line infrastructure'
cliNodeSourceUsers=1
# Default scripts are used by the command line infrastructure
cliUseDefaultScripts=true
# Single thread executes scenario 'create node sources with ssh infrastructure'
sshNodeSourceUsers=1
# Node source with two nodes is created per iteration
createNodeSourceNodesPerHost=2

# Others parameters from Example1 aren't changed:

# RM will be started on the host1
rm.deploy.rmHost=host1
# Don't set any options for the JVM running RM
rm.deploy.javaOpts=
# RM should clean it's database on start-up
rm.deploy.dropDB=true
# Host where RM will deploy nodes
rm.deploy.rmNodesHosts=host2,host3
# RM will start two nodes on each host2 and host3 
rm.deploy.rmNodesPerHosts=2

# Number of dummy RM listeners which can be registered to load RM event dispatching
rmListenersNumber=0

# Number of threads executing 'request nodes' scenario            
nodeRequestUsers=1
nodeRequestTopology=ARBITRARY
# Request one node per iteration
requestedNodesNumber=1
# Use selection script for nodes request
useSelectionScript=true
</pre>
<p>
Run test with this configuration, now test report should contain information about three scenarios.  
</p>

<h3><a id="examples_scheduler">Scheduler test</a></h3>
<p>
Here is an example of the simplest Scheduler test configuration: RM  and Scheduler are deployed automatically, pnp protocol is used.
</p>
<p>
General parameters are set in the <b>common.test.properties</b>:
</p>
<pre>
# Path to the jmeter, for example /user/userName/home/jakarta-jmeter-2.5.1
jmeterhome=&ltpath to jmeter&gt

# Run tests for one minute
testTime=60

# Immediately stop execution in case of error
stopOnError=true

# Path to the java executable, for example /user/userName/home/jdk/bin/java
javaPath=&ltpath to java executable&gt

# Path to the tested Scheduler project, for example /user/userName/home/Scheduler
schedulingPath=&ltpath to the tested Scheduler project&gt

# Use pnp protocol to deploy RM
test.deploy.protocol=pnp

# Parameters related to the PAMR router (empty since pnp protocol is used)
test.deploy.pamr.startNewRouter.host=
test.deploy.pamr.startNewRouter.args=
test.deploy.pamr.startNewRouter.port=
</pre>
<p>
RM deployement parametes should be set in the <b>rm.test.properties</b>. RM will be deployed on the host1 and it will
deploy two nodes on the both host2 and host3:
</p>
<pre>
# RM will be started on the host1
rm.deploy.rmHost=host1
# Don't set any options for the JVM running RM
rm.deploy.javaOpts=
# RM should clean it's database on start-up
rm.deploy.dropDB=true
# Host where RM will deploy nodes
rm.deploy.rmNodesHosts=host2,host3
# RM will start two nodes on each host2 and host3 
rm.deploy.rmNodesPerHosts=2
# RM tests aren't run, this parameter should be empty
createNodeSourceHosts=
</pre>
<p>
And configuration of the Scheduler deployment and parameters of the executed scenarios should be set in the <b>scheduler.test.properties</b>.
Scheduler will be started on the same host as RM, 
</p>
<pre>
# Start Scheduler on the host1
scheduler.deploy.schedulerHost=host1
# Don't set any options for the JVM running Scheduler
scheduler.deploy.javaOpts=
# Scheduler should clean it's database on start-up
scheduler.deploy.dropDB=true

# Number of dummy Scheduler listeners which can be registered to load Scheduler event dispatching
schedulerListenersNumber=0

# Submitted test jobs will use dynamic selection script with different content on each iteration 
submitUseSelectionScript=true
submitSelectionScriptDynamicContent=true
submitSelectionScriptTypeDynamic=true

# Single thread executes scenario 'submit simple java task'
simpleJavaTaskUsersNumber=1

# Single thread executes scenario 'submit simple native task'
simpleNativeTaskUsersNumber=1

# Number of threads executing otheres scenarios is set to zero to don't run these scenarios        
multiNodeSubmitUsersNumber=0
submitAndKillUsersNumber=0
submitAndKillTasksUsersNumber=0
submitDependentTasksUsersNumber=0
replicateTasksUsersNumber=0
loopTasksUsersNumber=0
sampleJobUsersNumber=0
failingTasksUsersNumber=0
schedulerConnectUsersNumber=0
</pre>
<p>
To execute test go to the 'performance' directory and run ant target which deploys Scheduler with RM and executes test: 
</p>
<pre>
>> ant deploy-rm-and-scheduler-and-execute-test
</pre>  
<p>
At the end of the successful run execution results are available in the 'performance/results':
</p>
<ul>
<li><b>scheduler1_detail.html</b> html report with information about each executed scenario (how many times scenario was executed, 
max, min and average time, execution errors if any)</li>
<li><b>jmeter.log</b> jmeter log, test  useful to analyze tests failures</li>
</ul>

<p>
If default <a href="#config_log">logging settings</a> weren't changed then 'performance/results' also contains Scheduler log file (PERFORMANCE_scheduler_server.log).
</p>

<p>
To run Scheduler test with PAMR protocol the same settings are needed as in the <a href="#example_rm_2">RM Example 2</a>. 
</p>
<p>
To configure execution of others scheduler scenario see <a href="#test_params_scheduler">here</a> list of all available scenarios and description of required configuration parameters.
</p>

</body>

</html>